## ISLR(4.1)-逻辑回归不是回归
#### 逻辑回归预测信用卡违约率


笔记要点：  
1.信用卡违约判断分类问题  
2.线性回归不可用(结果大于1)  
3.逻辑回归模型  
-- 估计回归系数（似然函数）   
-- 预测 （公式带入）  
-- 多元逻辑回归  
-- 多类别逻辑回归
### 1. 违约率判定分类问题
**Context**:  
 An online banking service must be able to determine **whether or not** a *transaction* being performed on the site is *fraudulent*, or an individual will *default* on his/her credit card payment 
- on the basis of the user's IP address, past transaction history, or annual *income* and monthly credit card *balance*  

![](https://imgkr2.cn-bj.ufileos.com/b17359ed-96f3-4b56-b4fa-f45b6d0a5d7d.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=rYgE12GVv6NizPzRCCfXJ1eZZJc%253D&Expires=1601332361)

There is a pronounced relationship between the predictor `balance` and the response `default`

### 2. 线性回归不可用
For a **binary** qualitative response, we could use the **dummy variable** to code the response `default`:

$$Y=
\begin{cases}
1,& \text{if  Default = Yes;}\\
0,& \text{if  Default = No.}
\end{cases}$$
And then fit a **linear regression** and predict an individual will *default* if $\hat{Y}>0.5$ and *not default* otherwise

**Disadvantages:**  
Even regression by least squares does make sense for a **binary** response, the $X\hat{\beta}$ obtained is in fact an estimate of $Y=Pr(default=Yes|X)$
- this make outside the [0,1] interval
- hard to interpret as probabilities!
![](https://imgkr2.cn-bj.ufileos.com/db6d6a4a-182e-42e5-afa2-4318e88aa871.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=QRi8KB4J21l7OFMC%252BmO8NiIurCA%253D&Expires=1601358333)


The dummy variable approach cannot be easily extended to accommodate qualitative responses with *more than two* levels
- Unless the response variable's values did take on a *natural ordering*, such as mild, moderate and severe (same gap)
- But different codings will still produce different linear models and result in a mess prediction



### 3. 逻辑回归不是回归！
*Logistic Regression* models the **probability** of each of the categories of a qualitative variable
- $Pr(default=Yes|balance)$ denotes the probability of default given `balance`
- this prediction will range between 0 and 1

If a company wishes to be *conservative* predicting individuals who are *at risk for default*:
- define a **lower threshold**, such as p(balance) > **0.1** will be classified **default = Yes**
#### 3.1 逻辑回归模型解决分类问题
To avoid the problem of using linear regression model $p(X)=\beta_0+\beta_1X$ to represent probabilites (out of range)
- Use **Logistic Function** to give ouput between 0 and 1  

$$p(X)=\frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}}$$
- Use Maximum Likelihood (3.2) to fit this model

**Odds发生比**
$$odds = \frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_1X}\in (0, \infty)$$
Values of odds close to **0 and $\infty$** indicate **very low and very high** probabilities of default
- On average 1 in 5 people will default
  - odds = $\frac{p(X)}{1-p(X)}=\frac{0.2}{1-0.2}=\frac{1}{4}$
- On average 9 in 10 people will default
  - odds = $\frac{p(X)}{1-p(X)}=\frac{0.9}{1-0.9}=9$
  
Odds are traditionally used ~~instead of probabilities~~ in **horse racing**, since they relate more naturally to the correct betting strategy

**Log-odd / logit**
$$\log(\frac{p(X)}{1-p(X)})=\ln e^{\beta_0+\beta_1X}=\beta_0+\beta_1X$$
We see that the logistic regression model has a **logit (transform)** that is linear in $X$
- in a linear regression model, *$\beta_1$* gives the average change in **$Y$** associated with a **one-unit increase** in $X$
- in a logistic regression model, *$\beta_1$* gives the average change of **log odds** associated with a **one-unit increase** in $X$
#### 3.2 估计回归系数(极大似然)
We could use (non-linear) least squares to estimate the unknown coefficient. 
- MLE has better statistical properties for fitting non-linear models


**Intuition behind ML**  
To seek estimates for $\beta_0$ and $\beta_1$ such that the predicted probability *$\hat{p}(x_i)$* of default for each individual, using **logistic function**, *corresponds as closely as possible* to the individual's observed default staus (1/0)
- If $p(x_i)$ is close to 1 for all individuals who default ($y_i=1$), and $p(x_{i'})$ is close to 0 for all who did not default:

$$L(\beta_0,\beta_1)=\prod_{i:y_i=1}p(x_i)\prod_{i':y_{i'}=0}(1-p(x_{i'}))$$
- *The Likelihood Function is maximized based on the chosen estimates $\hat{\beta_0}$ and $\hat{\beta_1}$*

![](https://imgkr2.cn-bj.ufileos.com/5699c951-0216-49ea-9e69-ff9e7d4aa18f.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=XQ5rVjsXcWiJrawM%252BxoCW6%252Br0bs%253D&Expires=1601368907)
Above shows the coefficient estimates and related information that result from *fitting a logistic regression model*
- $\hat{\beta_0}=-10.6513$ is not of interest, its main purpose is to *adjust the average fitted* probabilities to the proportion of ones in the data
- $\hat{\beta_1}=0.0055$ indicates a one-unit increase in `balance` is associated with an increase in the *log odds of default* by 0.0055 units

**Hypothesis Test**  
The **z-statistic** associated with $\beta_1$ is equal to **$\hat{\beta_1}/SE(\hat{\beta_1})$**
  - large z-value indicates the evidence against null hypothesis:
  $$H_0: \beta_1=0, \ p(X)=\frac{e^{\beta_0}}{1+e^{\beta_0}}$$
  - small p-value also reject $H_0$
    - there is an association between *balance* and *probability of default*

#### 3.3 基于信用卡月度余额预测违约概率
Given $\hat{\beta_0}=-10.6513$, $\hat{\beta_1}=0.0055$, 
$\hat{p}(X=1000) =0.00576$, $\hat{p}(X=2000) =0.586$
- huge difference in **probability of default** between balance = 1000 and balance = 2000

**学生身份对于违约概率的影响**
![](https://imgkr2.cn-bj.ufileos.com/26b10234-9d84-49ca-a97f-392c377f486d.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=KwmrID9TrHtfcyOjudIEAHkR5Pg%253D&Expires=1601373104)
$\hat{p}(default=Yes|X=1) =0.0431$ , $\hat{p}(default=Yes|X=0) =0.0292$
- Students tend to have **higher** default probabilities than non-students
#### 3.4 多元逻辑回归(#$X_i$ > 2)
Let $X=(X_1,...,X_p)$ be p predictors:
$$\log(\frac{p(X)}{1-p(X)})=\beta_0+\beta_1X+...+\beta_pX_p$$
$$  $$

$$p(X)=\frac{e^{\beta_0+\beta_1X+...+\beta_pX_p}}{1+e^{\beta_0+\beta_1X+...+\beta_pX_p}} $$  

Use Maximum Likelihood Method to estimate $\beta_0,...,\beta_p$
![](https://imgkr2.cn-bj.ufileos.com/eca0f591-69d1-41f9-ab96-1acd2c3e9382.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=UnVI8aUs0kNhuYMBRDSa73pOeV4%253D&Expires=1601372319)
Compare `Student` in Table 4.3 with Table 4.2, it seems to be paradox:
- negative vs positive to default  
- the negative coefficient for `student` in the multiple logistic regression indicates that for a **fixed value** of `balance` and `income`,
  - a student is **less likely** to default than a non-student
- Figure Left: Student default rate is **at or below** that of the non-student default rate for every value of *balance*

**矛盾原因 & 主要矛盾**  
the **overall** student default rate is **higher** than the non-student default rate(**the horizontal broken lines**)
- there is a positive coefficient for *student* in the single variable logistic regression
![](https://imgkr2.cn-bj.ufileos.com/0f8e8b2a-0d13-4cfc-8879-e80630a3f91d.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=CzKsWuOEW0vsmMYphE3b50quZXQ%253D&Expires=1601374008)

**业务逻辑**  
Students tend to hold higher levels of **debt**, which is in turn associated with higher probability of **default**
- they are more likely to have **large credit card balances**, which tend to be associated with high default rates!

**风险控制**  
Thus, even though a student with a **given credit card balance** will tend to have a **lower probability** of default than a non-student with the **same** credit card balance. 
- the fact that students on the whole tend to have **higher credit card balances**
  - overall, students tend to default **at a higher rate** than non-students.

学生违约率比非学生的要高，这点对信用卡公司决定应该对谁提供信用非常重要，如果不考虑任何关于学生信用卡余额信息，贷款给一个学生的风险要比贷款给非学生的要大
- 但对同等信用卡余额而言，学生的风险要比非学生的小
- 混淆现象(confounding)：只用一个预测变量得到的结果可能与多个预测变量得到的结果完全不一样, 尤其是当这些因素之间存在相关性时更是如此

**概率计算**  
Credit card balance = 1500 dollars
income = $40K

$$\hat{p}(X)=
\begin{cases}
0.058,& \text{if  Student = Yes;}\\
0.105,& \text{if  Student = No.}
\end{cases}$$
#### 3.5 逻辑回归解决多分类问题(#$Y_i$ > 2)
The two-class logistic regression models have multiple-class extensions but not be used often:
$$Pr(Y=Class_3|X)$$

$$=1-Pr(Y=C_1|X)-Pr(Y=C_2|X)$$
- Linear Discriminant Analysis(LDA) will solve this! (NEXT NOTE)
  - is stable when the classes are well-separated, the parameter estimates for the logistic regression model are **unstable**

### 4. 参考：
- Introduction to Statistical Learning (ISL)
- 《老董聊卡》
- 《极客时间 - 人工智能 & 机器学习》
- 校对：Wendy(Tiantian) Wang
###### TOGO: （4.4）线性判别分析(LDA)
