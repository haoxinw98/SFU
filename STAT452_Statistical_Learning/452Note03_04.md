## ISLR(3.3)-信用卡数据中的潜在问题
回归模型中六个潜在的问题:
- 共线性(Collinearity)
- 误差项自相关(Correlation of Error terms)
- 误差项方差非恒定(Non-constant variance)
- 离群点(Outliers)
- 高杠杆点(High-leverage Points)
- 非线性(Nonlinearity Relationship)

### 问题1:额度与信用评分的高度共线性
![](https://imgkr2.cn-bj.ufileos.com/21742bc5-cb06-4115-9602-e405c76839a9.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=rh7EEwsZwKLa%252F70zeSLKEmq32WU%253D&Expires=1601071196)

共线性是指两个或更多的预测变量高度相关，导致难以分离出单个变量对响应变量的影响
- 信用额度`limit`和信用评分`rating`往往同时增加和减少，很难确定单一变量与信用卡债务`balance`的相关性
#### 共线性的问题
具有高度共线性两个变量的RSS contour plot（等高线）中，等高线之间非常狭窄
- 因此数据的微小变化导致RSS最小的系数估计（最小二乘估计）有很大的不确定性
![](https://imgkr2.cn-bj.ufileos.com/ae8c3818-7f1b-434e-a759-cc5aa9d458ba.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=4X2RWWUefrnPsFygJBiI6xaHWlU%253D&Expires=1601071345)

由于共线性降低了回归系数的准确性，这导致$\hat{\beta_j}$ 的标准误差增加
- 因为每个预测值(x)的 $t-statistic$ 是由 $\hat{\beta_j}$ 除以其标准误差得到的, 所以共线性降低了 $t$ 值
- 因此我们可能无法拒绝 $H_0:\beta_j=0$ 
  - The **power** ofthe hypothesis test, which is the **probability** of correctly detecting a **non-zero** coefficient is **reduced** by collinearity
  
![](https://imgkr2.cn-bj.ufileos.com/c27b3bc7-1fed-42c4-89db-4d1b8a6b31f6.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=55%252BC3ikj493YVcJ2aTRIXY5tn7g%253D&Expires=1601072331)

- 由于共线性的存在，`limit`  变量的重要性被掩盖了

*正所谓*：**一山难容二虎，一个模型难容两个共线变量**

#### 共线性的检测
**Correlation Matrix**  
预测变量的相关系数矩阵中出现**绝对值最大的元素**表示有**一对**变量高度相关, 
- 因此数据中可能存在共线性问题
- 但相关系数矩阵无法检测到 **三个或更多**变量之间是否存在**多重共线性**：


**Variance Inflation Factor**  
计算方差膨胀因子(VIF)评估多重共线性：
$$VIF(\hat{\beta_j})=\frac{1}{1-R_{X_j|X_{-j}}^2}$$ 
其中$R_{X_j|X_{-j}}^2$是 $X_j$ 对所有预测变量回归的$R^2$
- VIF is the ratio of the variance of $\hat{\beta_j}$ when fitting the full model divided by the variance of $\hat{\beta_j}$ if fit on its own
- 当$R_{X_j|X_{-j}}^2 = 0$, VIF=1, 表示完全不存在共线性
- 当$R_{X_j|X_{-j}}^2$ => 1, 经验法则：VIF超过5或者10就表示有共线性问题
- The predictors {age, rating, limit} have VIF values of {1.01, 160.67, 160.59}
  - 信用卡数据集中存在相当大的共线性！

#### 共线性的解决方案
**从回归中剔除一个问题变量**  
当我们作` balance `对`age`和`limit`不包含`rating`的回归：
- 在不需对拟合作出妥协的前提下, 手动剔除一个多余的变量解决共线性问题
- $VIF \approx 1,$ 
- $R^2: 0.754 => 0.75$

**融合两个共线变量**  
把共线变量组合成一个单一的预测变量：
- 对标准化后的`limit`和`rating`求平均创建新变量`credit worthiness`
### 问题2:误差项自相关
线性回归中的一个重要假设是误差项$\epsilon_1, ..,\epsilon_n$**不相关**:
- $\epsilon_n>0$ 完全不能判断$\epsilon_{n+1}$ 的正负
- 回归系数和拟合值的标准误的计算基于不相关假设

**误差项自相关导致的问题**：  
估计标准误差往往会低估了真实的标准误差
- 95%CI包含真实参数的实际概率远远低于0.95
- p-value降低导致错误的结论，认为参数是统计显著的
- 模型的置信度无法保证

假如重复了样本量为n的样本 ==> 2n
- 对2n个样本对参数估计和对n个样本对估计相同，但后者CI对宽度是前者的$\sqrt{2}$倍

**时间序列中的误差相关性**  
如果相邻的时间点产生的误差有正相关关系,
- 在残差图中有跟踪现象（tracking）,否则就是上下波动
![](https://imgkr2.cn-bj.ufileos.com/2baf9bed-98b1-4e6a-9e24-6f273e87b18e.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=5tM0bcy%252B7tiFukvumnqozLfp4nA%253D&Expires=1601069972)

假设【误差项不相关】对线性回归和其他统计方法都很重要
- 良好的实验设计(控制变量、环境)可以降低误差项自相关带来的风险
### 问题3:误差项方差非恒定
线性回归模型的另一个重要假设是误差项的方差是恒定的
- $VAR(\epsilon_i)=\sigma^2$
- 线性模型中的假设检验和标准误差、置信区间的计算都依赖于这一假设
- 然而真实情况下，误差项的方差是**非恒定的**
  - 可能随着响应值的增加而增加

**凹函数(concave function)变换**
![](https://imgkr2.cn-bj.ufileos.com/97618a9a-a2b8-42db-b8f1-03c32a78efed.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=LSI%252BlZzEdApXyLZIhi%252BLmhpPZ0k%253D&Expires=1601069762)
残差图呈漏斗形(`funnel shape`)，说明误差项方差**非恒定**或存在**异方差性**
- 当残差随拟合值增加而增加，用**凹函数**对响应值 $y$ 做变换, 比如 $\log Y$ 和 $\sqrt{Y}$
- 这种变换使较大的响应值有**更大的收缩(shrinkage)**==> 降低异方差性

**加权最小二乘(weighted least squares)**
当每个原始 $X_i$ 与方差 $\sigma^2$ 无关：
- e.g. the $i^{th}$ response could be an average of $n_i$ raw observations
- 全部 $X_i$ 均值方差为 $\sigma_i^2=\sigma^2/n_i$
- simple remedy: 用加权最小二乘法拟合模型，即权重与方差的倒数成正比：
  - i.e. $w_i=n_i$
### 问题4：异常值(Outlier)
预测变量的异常值通常对最小二乘拟合几乎没有影响, 但是对RSE和$R^2$有影响：
- $R^2$ ：0.892 ==> 0.805 
- RSE： 0.77 ==> 1.09 when the outlier is removed ==> included in the regression
- Since RSE is used to compute all CIs and p-values,
  - such a dramatic increase caused by a single data point can have implications for the interpretation of the fit  
  
![](https://imgkr2.cn-bj.ufileos.com/4c074016-2160-4c8e-88ab-49b021dd77c9.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=BT2UdGAo1gCP0cm7fnn27q3vL3o%253D&Expires=1601069266)

**学生化残差 - studentized residual**  
实践中很难确定残差多大可以确定是异常点
- 学生化残差：每一个由残差$e_i$除以它的估计标准误差得到
- 学生化残差绝对值大于3的 $X_i$ 可能是异常值

异常值如果显而易见是数据采集或者记录中的错误导致，就删掉
- 如果一个异常值可能不是由失误导致的，这意味着模型存在缺陷（e.g. 缺少关键预测变量）
### 问题5：高杠杆点(high-leverage point)
与异常值（$y_i$ 远离模型预测值的点)对比，高杠杆点是 $x_i$ 远离其他 $x$ 的异常点

高杠杆点对回归直线的估计有很大影响，这可能会导致整个拟合的失效
- 在简单线性回归中，找到高杠杆点容易(画图)
- 在多元线性回归中，为了量化观测点的杠杆，可以计算**杠杆统计量:leverage statistic**
$$h_i=\frac{1}{n}+\frac{(x_i-\bar{x})^2}{\sum_{i=1}^n(x_i)}$$
The Leverage Statistic increases with the distance of $x_i$ from $\bar{x}$
- $h_i$ is always between 1/n and 1, and the average leverage for all obserations is always equal to (p+1)/n，超过的对应点可能有较高的杠杆作用
![](https://imgkr2.cn-bj.ufileos.com/2781561b-2986-4536-a731-7eaddf16513c.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=xRfMIvyX%252Bc6BemqN0N3IETHCUhQ%253D&Expires=1601067773)

### 问题6：非线性关系
在【统计笔记06】中已经总结通过多项式直接扩展线性模型之外，残差图也可以识别非线性关系
![](https://imgkr2.cn-bj.ufileos.com/0c780adc-4c44-4d39-bbbc-70e34d345ffd.jpeg?UCloudPublicKey=TOKEN_8d8b72be-579a-4e83-bfd0-5f6ce1546f13&Signature=w%252FFJe1sO8Glctpi%252BZxTLYMFIngk%253D&Expires=1601058702)

如果残差图表明数据中存在非线性关系，可以在模型中使用预测变量的**非线性变换**
- such as  $\log X, \sqrt{X}, X^2$
### 7. 参考：
- Introduction to Statistical Learning (ISL)
- 《老董聊卡》

###### TOGO: （5.1）重抽样方法&交叉验证
