11 Pages | 
- Section 10.1 Virtual Memory Background | Page 2 - 5
- Section 10.2 Demand Paging | Page 6 - 11
### 1. Introduction
All memory management strategies have the same goal:
- To Keep many processes in memory simultaneously to allow multiprogramming
- However, they tend to require that an **entire process** be in memory **before** it can execute

Virtual Memory allows the execution of processes that are not completely in memory
- programs can be larger than physical memory of the system!!!

Further, virtual memory **abstracts** main memory into an extremely large, uniform array of storage, separating logical memory as viewed by the programmer from physical memory
- To free programmers from the concerns of memory-storage limitations

#### 1.1 Memory-Management requirement:
- Necessary: The Instructions being executed must be in **physical memory**
- Restriction: Place the **entire** logical address space in physical memory
- Unfortunate: since it limits the size of a program to the size of physical memory ( program < physical memory)

**Dynamic Linking** can help to **ease this restriction**
  - but it requires special precautions (预防）and extra work by the programmer
#### 1.2 Entire Program is not needed at the same time
In many cases, no need to load the entire program into memory:
- Programs often have code to handle unusual error conditions
  - since these errors seldom, if ever, occur in practice, this code is almost never executed
- Arrays, lists, and tables are often allocated more memory than they actually need
- Certain options and features of a program may be used rarely. 
  - For instance, the routines on U.S. government computers that balance the budget have not been used in many years
  
#### 1.3 Benifits
Even in those cases where the entire program is needed,
- it may not all be needed **at the same time**

Execute a program that is only partially in memory confer many benefits:
- A program would no denpend on physical memory
  - Users may write programs for an **extremely large virtual** address space, simplifying the programming task
- Because each program could take less physical memory, more programs could be run at the same time
  - with a corresponding increase in **CPU Utilization** and **throughput**
  - but with no increase in response time or turnaround time
- Less I/O would be needed to load or swap portions of programs into memory, so each program would run faster
#### Overlays(???)
We read in a block of code at a time, and when that block is finished
- we read the next block of code into the same place and start the PC at the beginning again

![](imgs/two_pass_assembler.jpeg)
#### Dynamic Loading (9.1.4 & VM W/O Hardware)
With dynamic loading, a routine is not loaded until it is called
- ALl routine are kept on disk in a relocatable load format
  - each program has a main routine that is loaded first, all other subroutines are replaced by stubs
    - stubs consist of code to load the actual subroutine from disk; once done the subroutine starts executing
    - subroutine stays in memory once loader for subsequent calls
- The main program is loaded into memory and is executed
  - when a routine needs to call another routine, the calling routine first checks to see whether the other routine has been loaded
  - If not, **the relocatable linking loader** is called to load the **desired** routine into memory and to update the program's address tables to reflect this change.
    - Then, control is passed to the **newly** loaded routine


The advantage of dynamic loading is that a routine is loaded only when it is needed.
- this method is particularly useful when **large amounts of code** are needed to handle **infrequently** occurring cases, such as error routines. ==> the portion that is used may be much smaller to load

Dynamic loading does not require Hardware Support from the OS
- OS may help programmer by providing library routines to implement dynamic loading

Problems with software solutions to VM:
- Complicated to implememt
- Difficult to automate
### 2. Demand Page
A demand-paging system is similar to a paging system with swapping (Sec.9.5.2) where processes reside in secondary memory(e.g.HDD) into frames
- Demand Paging explains one of the primary benefits of virtual memory - by loading **only the portions** of programs that are needed, memory is used more efficiently
- Pages (that are never accessed) are thus never loaded into physical memory

#### 2.1 Access Protection:

Valid/Invalid bit for each page in page table
- The page-table entry for a page that is not currently in memory is simply marked **invalid""
  - this will have no effect if the process never attempts to access that page
- in demand paging it will indicate that the address was invalid or it will indicate if the referenced page is currently in memory or in secondary storage (hardware support)

When the bit is set to "valid", the associated page is 
- both legal and in memory

If the bit is set to "invalid", the page either is 
- not valid, not in the logical address space of the process
- valid but is currently in secondary storage

If the process tries to access a page **that was not brought**(=invalid) into memory:
- access to an invalid page causes a `page fault`
- the paging hardware, in translating the address through the page table
  - will notice that the invalid bit is set
  - causing a trap to the OS
    - trap is the result of the **OS'failure** to bring the desired page into memory


!()[imgs/handle_page_fault.jpeg]
#### 2.2 Procedure for handling this page fault
Step 1: check an internal table (usually keep with the PCB)
- for this process to determine whether the reference was alid or an invalid memory access

Step 2: If the reference was invalid, we terminate the process
- if it was valid but we have not yet brought in that page
  - we now page it in

Step 3: Find a Free Frame in Physical Memory
- By taking one from the free-frame list

Step 4: Schedule a Secondary Storage operation 
- to read the desired page into the newly **alocated frame**

Step 5: When the storage read is complete,
- Modify the internal table kept with the process and the page table
  - to indicate that the page is now in memory

Step 6: Restart the instruction that was interrupted by the trap
- the process can now access the page as though it had always been in memory

#### 2.3 Ways to execute with no pages in memory

When the OS sets the instruction pointer to the first instruction of the process
- which is on a non-memory-resident page,
- the process immediately **faults for the page** and do not load any pages

**Preparing**: Load a few pages that we expect the process to need immediately

After this page is brought into memory, 
- the process continues to execute, faulting as necessary until every page that it needs is in memory
- at that point, it can execute with no more faults
  - **Pure demand paging**: never bring a page into memory until it is required

The hardware support for demamd paging is same as for paging and swapping
- Page Table with **valid/invalid bit**
- Secondary Memory

Notice that by using demand paging we have completely separated logical memory and physical memory
- we have removed memory size constraints!

#### 2.4 Restart Instruction
Requirement for demand paging: 
- Ability to restart any instrctuion after a page fault
- because we save the state (registers, condition code, instruction counter) of the interrupted process when page fault occurs
- we must be able to restart the process in **exactly** the same place and state,
  - except that the desired page is now in memory and is accessible
  - => Paging should be **transparent!**

If the page fault occurs on the **instruction fetch** ,
- we can restart by fetching instruction again.

If a page fault occurs while we are fetching an operand,
- we must fetch and decode the instruction again
- and then fetch the operand

E.g. C = A + B 
1. Fetch and Decode the instruction (ADD)
2. Fetch A
3. Fetch B
4. Add A and B
5. Store the sum in C 

If we fault when we try to store in C
- because C is in a page NOT currently in memory
- we will have to get the desired page, bring it in, correct the page table,
  - and restart the instruction !

The restart will require the first four steps again
- but not much repeated work (less than one complete instruction)
- only necessary when a page fault occurs

E.g. MOV (R2)++, --(R3)
1. Copies the contents of the location pointed to by R2 into the location pointed to by R3
2. R2++ after being dereferenced
3. R3-- before it is dereferenced

If dereferencing R3 causes a page fault
- CANNOT just restart the instruction since the page fault occurs mid-instruction
  - R2 and R3 have been modified

### 2.5 Performance (Page 10)
If P is the fraction of memory accesses that cause a page fault,
- the effective access time 
  - (1 - P) x (memory access time) + P x (page fault service time)

E.g. 
- Memory Access time = 1 us
- Page Fault Service time = 10 ms (= 10,000 us = 10,000,000 ns)
  - A typical hard disk has an average latency of 3 ms
  - A seek of 5 ms
  - A transfer time of 0.05 ms
  - Average Page-Switch time is close to 8 ms
- Page Fault Frequency = 1/1000  
Eff.Acc.Time = (1 - 1/1000) x 1 us + 1/1000 x 10 ms = 11 us (slowdown factor of 11x)
- Page Faults must be kept very rare!


### Page Faults (Page 11 | Quiz 5 Q6)
1. Trap to the OS
2. Save the registers and process state
3. Determine that the interrupt was a page fault
4. Check that the page reference was legal, and determine the location of the page in secondary storage
5. Issue a read from the storage to a free frame:
- Wait in a queue until the read request is serviced
- Wait for the device seek and/or latency time
- Begin the transfer of the page to a free frame  

6. While waiting, allocate the CPU core to some other process
- assuming that the CPU is allocated to another process while the I/O occurs
- allow multiprogramming to maintain CPU utilization
- But requires additional time to resume the page-fault service routine
  - when the I/O transfer is complete
7. Receive an interrupt from the storage I/O subsystem (I/O completed)
8. Save the registers and process state for the other process
- If the Step 6 is executed
9. Determine that that the interrupt was from the secondary storage device
10. Correct the page table and other tables
- to show that the desired page is now in memory
11. Wait for the CPU core to be allocated
- to this page faulting process again
12. Restore the registers, process state, and new page table, 
- and then resume the interrupted instruction

There are three major task components of the page-fault service:
- Service the page-fault interrupt
- Read in the page
- Restart the process

The first and third tasks can be reduced, with careful coding, to several hundred instructions

#### TOGO: Lec 19、20, Page Replacement Algorithms
